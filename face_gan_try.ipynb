{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOg7yGXYNS8tZm4tp4MsH1k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aapng-cmd/ML-s-Neuro/blob/main/face_gan_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O_vfRE9VQmLQ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# !ls\n",
        "# !rm -rf facerecon_v2.zip faces\n",
        "# !wget http://upos-repo.ru:4444/facerecon_v2.zip\n",
        "# !unzip facerecon_v2.zip\n",
        "# !rm facerecon_v2.zip\n",
        "# !mv t faces\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "metadata": {
        "id": "_ZebyToMibPp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.load_dataset()\n",
        "\n",
        "    def load_dataset(self):\n",
        "        for dir_name in os.listdir(self.root_dir):\n",
        "            angle_x, angle_y = dir_name.split(\"_\")\n",
        "            angle_x, angle_y = int(angle_x), int(angle_y)\n",
        "            dir_path = os.path.join(self.root_dir, dir_name)\n",
        "            for file_name in os.listdir(dir_path):\n",
        "                if file_name.endswith(\".jpg\"):\n",
        "                    img_path = os.path.join(dir_path, file_name)\n",
        "                    img = cv2.imread(img_path)\n",
        "                    img = cv2.resize(img, (128, 128))  # Resize images to 128x128\n",
        "                    self.images.append(img)\n",
        "                    self.labels.append((angle_x, angle_y))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return {\n",
        "            \"image\": img,\n",
        "            \"label\": label\n",
        "        }\n",
        "\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = FaceDataset(\"faces\", transform=data_transform)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "L2Tz15ZrQtZ0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# Define the generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 128)  # input layer (2) -> hidden layer (128)\n",
        "        self.fc2 = nn.Linear(128, 128*128*3)  # hidden layer (128) -> output layer (128x128x3)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # activation function for hidden layer\n",
        "        x = self.tanh(self.fc2(x))  # activation function for output layer\n",
        "        x = x.view(-1, 3, 128, 128)  # reshape to 128x128x3\n",
        "        return x\n",
        "\n",
        "# Define the discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(128*128*3, 128)  # input layer (128x128x3) -> hidden layer (128)\n",
        "        self.fc2 = nn.Linear(128, 1)  # hidden layer (128) -> output layer (1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x.view(-1, 128*128*3)))  # activation function for hidden layer\n",
        "        x = self.sigmoid(self.fc2(x))  # activation function for output layer\n",
        "        return x\n",
        "\n",
        "# Initialize the generator and discriminator\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "if os.path.exists(\"generator.pth\") and os.path.exists(\"discriminator.pth\"):\n",
        "    generator.load_state_dict(torch.load('generator.pth', map_location=torch.device(device)))\n",
        "    discriminator.load_state_dict(torch.load('discriminator.pth', map_location=torch.device(device)))\n",
        "\n",
        "\n",
        "# Define the loss functions and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=0.01)\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qgRuSdHOX-V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f82c551-0bd6-4cb4-866d-bb38a30da092"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the generator to the GPU\n",
        "generator.to(device)\n",
        "\n",
        "# Move the discriminator to the GPU\n",
        "discriminator.to(device)\n",
        "\n",
        "def checker(generator, label=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Generate fake labels\n",
        "    if label == None:\n",
        "        fake_labels = torch.randn(1, 2).to(device)\n",
        "    else:\n",
        "        fake_labels = torch.tensor(label)\n",
        "    # Generate fake image\n",
        "    fake_image = generator(fake_labels)\n",
        "\n",
        "    # Convert the generated image to a numpy array\n",
        "    fake_image = fake_image.detach().cpu().numpy()\n",
        "\n",
        "    # Remove the batch dimension\n",
        "    fake_image = fake_image[0]\n",
        "\n",
        "    # Transpose the image to (height, width, channels)\n",
        "    fake_image = fake_image.transpose((1, 2, 0))\n",
        "\n",
        "    # Clip the image values to the range [0, 1]\n",
        "    fake_image = np.clip(fake_image, 0, 1)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(fake_image)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Train the GAN\n",
        "EPOCHS = 100\n",
        "l = len(data_loader)\n",
        "for epoch in range(EPOCHS):\n",
        "    for i, data in enumerate(data_loader):\n",
        "        # Get the real images and labels\n",
        "        real_images, real_labels = data[\"image\"], data[\"label\"]\n",
        "        real_images = real_images.to(device)\n",
        "        real_labels = torch.tensor([label[0] for label in real_labels]).unsqueeze(1).to(device)\n",
        "\n",
        "        # Generate fake images\n",
        "        noise = torch.randn(real_labels.size(0), 2, device=device)\n",
        "        fake_images = generator(noise)\n",
        "\n",
        "        # Train the discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "        real_output = discriminator(real_images)\n",
        "        fake_output = discriminator(fake_images.detach())\n",
        "        d_loss_real = criterion(real_output, torch.ones(real_output.size(0), 1, device=device))\n",
        "        d_loss_fake = criterion(fake_output, torch.zeros(fake_output.size(0), 1, device=device))\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Train the generator\n",
        "        optimizer_g.zero_grad()\n",
        "        fake_output = discriminator(fake_images)\n",
        "        g_loss = criterion(fake_output, torch.ones(fake_output.size(0), 1, device=device))\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"{i} / {l}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1} / {EPOCHS}, D loss: {d_loss.item():.4f}, G loss: {g_loss.item():.4f}\")\n",
        "    checker(generator)"
      ],
      "metadata": {
        "id": "YTvIfh6_HHN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7adb1650-2654-4944-ad8b-1d01407b1fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 5023\n",
            "100 / 5023\n",
            "200 / 5023\n",
            "300 / 5023\n",
            "400 / 5023\n",
            "500 / 5023\n",
            "600 / 5023\n",
            "700 / 5023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(generator.state_dict(), 'generator.pth')\n",
        "# torch.save(discriminator.state_dict(), 'discriminator.pth')\n",
        "# from google.colab import files\n",
        "# files.download(\"generator.pth\")\n",
        "# files.download(\"discriminator.pth\")"
      ],
      "metadata": {
        "id": "p32BUm0tQoVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}