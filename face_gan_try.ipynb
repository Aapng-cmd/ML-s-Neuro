{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aapng-cmd/ML-s-Neuro/blob/main/face_gan_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "O_vfRE9VQmLQ"
      },
      "outputs": [],
      "source": [
        "# !ls\n",
        "# !rm -rf facerecon_v2.zip faces discriminator.pth generator.pth\n",
        "# !wget http://upos-repo.ru:4444/facerecon_v3.zip\n",
        "# !unzip facerecon_v3.zip\n",
        "# !rm facerecon_v3.zip\n",
        "# !mv t faces\n",
        "# # !wget http://upos-repo.ru:4444/discriminator.pth\n",
        "# # !wget http://upos-repo.ru:4444/generator.pth\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Tz15ZrQtZ0",
        "outputId": "185716d1-bd7c-4499-96fa-e9900aeff67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.load_dataset()\n",
        "\n",
        "    def load_dataset(self):\n",
        "        for dir_name in os.listdir(self.root_dir):\n",
        "            angle_x, angle_y = dir_name.split(\"_\")\n",
        "            angle_x, angle_y = int(angle_x), int(angle_y)\n",
        "            dir_path = os.path.join(self.root_dir, dir_name)\n",
        "            for file_name in os.listdir(dir_path):\n",
        "                if file_name.endswith(\".jpg\"):\n",
        "                    img_path = os.path.join(dir_path, file_name)\n",
        "                    self.image_paths.append(img_path)\n",
        "                    self.labels.append((angle_x, angle_y))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        # Move image to GPU\n",
        "        return {\n",
        "            \"image\": img.to(device),  # Move image to the device (GPU or CPU)\n",
        "            \"label\": torch.tensor(label).unsqueeze(1).to(device)  # Move label to the device\n",
        "        }\n",
        "\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = FaceDataset(\"faces\", transform=data_transform)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "# Move the dataset and data loader to the GPU\n",
        "# dataset.images = [img.to(device) for img in dataset.images]\n",
        "# dataset.labels = [label.to(device) for label in dataset.labels]\n",
        "# data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgRuSdHOX-V1",
        "outputId": "c9c4d237-5e47-4d88-bc61-f7b39cbb3a4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=49152, out_features=128, bias=True)\n",
              "    (1-18): 18 x Linear(in_features=128, out_features=128, bias=True)\n",
              "    (19): Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              "  (sigmoid): Sigmoid()\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# Define the generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 128)  # input layer (2) -> hidden layer (128)\n",
        "        self.fc2 = nn.Linear(128, 128*128*3)  # hidden layer (128) -> output layer (128x128x3)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # activation function for hidden layer\n",
        "        x = self.tanh(self.fc2(x))  # activation function for output layer\n",
        "        x = x.view(-1, 3, 128, 128)  # reshape to 128x128x3\n",
        "        return x\n",
        "\n",
        "# Define the discriminator network\n",
        "# Nothing is better than previous model.\n",
        "\n",
        "\n",
        "# Initialize the generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "if os.path.exists(\"generator.pth\") and os.path.exists(\"discriminator.pth\"):\n",
        "    generator.load_state_dict(torch.load('generator.pth', map_location=torch.device(device)))\n",
        "    discriminator.load_state_dict(torch.load('discriminator.pth', map_location=torch.device(device)))\n",
        "\n",
        "\n",
        "# Define the loss functions and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=0.01)\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "d_losses = []\n",
        "g_losses = []\n",
        "# Move the generator to the GPU\n",
        "generator.to(device)\n",
        "\n",
        "# Move the discriminator to the GPU\n",
        "discriminator.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTvIfh6_HHN-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "\n",
        "def checker(generator, label=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Generate fake labels\n",
        "    if label == None:\n",
        "        fake_labels = torch.randn(1, 2).mul(60).sub(30).to(device)\n",
        "    else:\n",
        "        fake_labels = torch.tensor(label)\n",
        "    # Generate fake image\n",
        "    fake_labels = fake_labels.to(device)\n",
        "    fake_image = generator(fake_labels)\n",
        "\n",
        "    # Convert the generated image to a numpy array\n",
        "    fake_image = fake_image.detach().cpu().numpy()\n",
        "\n",
        "    # Remove the batch dimension\n",
        "    fake_image = fake_image[0]\n",
        "\n",
        "    # Transpose the image to (height, width, channels)\n",
        "    fake_image = fake_image.transpose((1, 2, 0))\n",
        "\n",
        "    # Clip the image values to the range [0, 1]\n",
        "    fake_image = np.clip(fake_image, 0, 1)\n",
        "\n",
        "    # Display the image\n",
        "    print(fake_labels)\n",
        "    plt.imshow(fake_image)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Train the GAN\n",
        "EPOCHS = 1000 ** 2\n",
        "l = len(data_loader)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    __ = time.time()\n",
        "    t = time.time()\n",
        "    for i, data in enumerate(data_loader):\n",
        "        # Get the real images and labels\n",
        "        real_images = data[\"image\"]\n",
        "        real_labels = data[\"label\"]\n",
        "\n",
        "        # Generate fake images\n",
        "        noise = torch.randn(real_labels.size(0), 2, device=device)\n",
        "        fake_images = generator(noise)\n",
        "\n",
        "        # Train the discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "        real_output = discriminator(real_images)\n",
        "        fake_output = discriminator(fake_images.detach())\n",
        "        d_loss_real = criterion(real_output, torch.ones(real_output.size(0), 1, device=device))\n",
        "        d_loss_fake = criterion(fake_output, torch.zeros(fake_output.size(0), 1, device=device))\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Train the generator\n",
        "        optimizer_g.zero_grad()\n",
        "        fake_output = discriminator(fake_images)\n",
        "        g_loss = criterion(fake_output, torch.ones(fake_output.size(0), 1, device=device))\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        if i % 100 == 99:\n",
        "            k = time.time() - t\n",
        "            d = k // (24 * 60 * 60)\n",
        "            k -= d * 24\n",
        "            h = k // (60 * 60)\n",
        "            k -= h * 60\n",
        "            m = k // 60\n",
        "            k -= m * 60\n",
        "            s = k\n",
        "            print(f\"{i+1} / {l+1}\", f\"Time per 100 data for '{device}' is: Days: {d}\\tHours: {h}\\tMinutes: {m}\\tSeconds: {s}\")\n",
        "            print(\"Mid check\")\n",
        "            checker(generator)\n",
        "            t = time.time()\n",
        "\n",
        "    k = time.time() - t\n",
        "    d = k // (24 * 60 * 60)\n",
        "    k -= d * 24\n",
        "    h = k // (60 * 60)\n",
        "    k -= h * 60\n",
        "    m = k // 60\n",
        "    k -= m * 60\n",
        "    s = k\n",
        "    print(f\"Epoch {epoch+1} / {EPOCHS}, D loss: {d_loss.item():.4f}, G loss: {g_loss.item():.4f}, Time per epoch is: Days: {d}\\tHours: {h}\\tMinutes: {m}\\tSeconds: {s:.2f}\")\n",
        "    checker(generator)\n",
        "    d_losses.append(d_loss.item())\n",
        "    g_losses.append(g_loss.item())\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(len(d_losses)), d_losses, label=\"Discriminator Loss\")\n",
        "    plt.plot(range(len(g_losses)), g_losses, label=\"Generator Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Discriminator and Generator Loss History\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8crYgdFeJPTG"
      },
      "outputs": [],
      "source": [
        "checker(generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p32BUm0tQoVs"
      },
      "outputs": [],
      "source": [
        "torch.save(generator.state_dict(), 'generator.pth')\n",
        "torch.save(discriminator.state_dict(), 'discriminator.pth')\n",
        "from google.colab import files\n",
        "files.download(\"generator.pth\")\n",
        "files.download(\"discriminator.pth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7LA4osE1oi6T62errNW5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}